{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Natural Language Processing is an interdisciplinary area of research bringing together insights from fields such as artifical intelligence, computational linguistics, statistics and computer science. The aim of NLP is to enable computers to understand and to process the natural langauges that are spoken and written by human beings. Researchers in the field of NLP have developed sophisticated tools and algorithms for machine translation, document summarisation and sentiment analysis. This notebook explains two specific preprocssing task in NLP: Part of speech tagging and Lemmatisation.  \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of speech tagging\n",
    "\n",
    "Part of speech (POS) taggers are applications which can produce data about the syntactic categories of words. Their aim is to determine the lexical categories of words. Using such POS taggers, we extract words in specific lexical categories, such as nouns, verbs, adjectives, and adverbs. \n",
    "\n",
    "Once you have imported the `nltk` library, you can generate such POS tags by making use of the `pos_tag()` method. This method demands a list of words as a parameter. \n",
    "\n",
    "`pos_tag()` is typically used in combination with a word tokenisation method such as `word_tokenize`. The output of this latter function can then be used as input to the `pos_tag()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize,pos_tag\n",
    "from tdmh import *\n",
    "\n",
    "quote = '''All the world is a stage, \n",
    "and all the men and women merely players'''\n",
    "\n",
    "words = word_tokenize(quote)\n",
    "words = remove_punctuation(words)\n",
    "pos = pos_tag(words)\n",
    "\n",
    "for p in pos:\n",
    "    print(p[0] + ' => ' + p[1] )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pos_tag()` methods returns a composite variable with two values. More specifically, it is a data structure that is called a *tuple*. The first value is the word that was tagged and the second value is the POS tag that was assigned to this word. You can access these values individually using square brackets. \n",
    "\n",
    "The meaning of all of the POS tags can be displayed by printing the output of the `nltk.help.upenn_tagset()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( nltk.help.upenn_tagset() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of codes and their meanings can [also be found online](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatisation \n",
    "\n",
    "English verbs can be used, in the past tense, in the present tense, in the continuous form or in the perfect form, and these different forms can evidently make it more difficult to search systematically for occurrences of a specific verb. The same can be the case for nouns. They can be used in the singular and in the plural form. In some situations, we simply want to find all occurrences of a word, regardless of declensions and inflections. In this context, lemmatisation can offer a solution.\n",
    "\n",
    "Lemmatisation is a process in which the conjugated forms of the words that are found in a text are converted into their base dictionary form. This base form is referred to as the lemma. \n",
    "\n",
    "You can lemmatise texts using the  `lemmatize()` method, which is part of the `WordNetLemmatizer` module of the `nltk` library. This method needs to be applied to indivual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "print( lemmatiser.lemmatize( 'books' ) )\n",
    "## prints 'book'\n",
    "\n",
    "print( lemmatiser.lemmatize( 'reads' ) )\n",
    "## prints 'read'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It some cases, it can be unclear precisely how words ought to be lemmatised. Certain homonyms may either be verbs or nouns, for instance, and, depending on their usage, they should be lemmatised to different forms. To help the lemmatiser to make such distinctions, we can add a second parameter to indicate the lexical category of the word to be lemmatised. The first statement in the code lemmatises the word 'recording' as a verb, and the second statement as a noun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( lemmatiser.lemmatize( 'recording' , 'v') )\n",
    "## 'record'\n",
    "\n",
    "print( lemmatiser.lemmatize( 'recording' , 'n' ) )\n",
    "## 'recording'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `lemmatize()` method does not use the Penn Treebank codes but the POS codes that have been defined for `wordnet`. It uses 'a' for adjectives, 'v' for verbs, 'n for nouns' and  'r' for adverbs. \n",
    "\n",
    "The code below shows you how you can lemmatise a whole sentence. The code firstly tokenises the words in the sentence that is given using `word_tokenize`. Next, the code generates the POS codes (from Penn Treebank) using `pos_tag`. These codes are then converted into `wordnet` codes used a new function named `ptb_to_wordnet()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "quote = '''We are such stuff as dreams are made on, \n",
    "and our little life is rounded with a sleep'''\n",
    "\n",
    "\n",
    "def ptb_to_wordnet(PTT):\n",
    "\n",
    "    if PTT.startswith('J'):\n",
    "        ## Adjective\n",
    "        return 'a'\n",
    "    elif PTT.startswith('V'):\n",
    "        ## Verb\n",
    "        return 'v'\n",
    "    elif PTT.startswith('N'):\n",
    "        ## Noune\n",
    "        return 'n'\n",
    "    elif PTT.startswith('R'):\n",
    "        ## Adverb\n",
    "        return 'r'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "    \n",
    "lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "words = word_tokenize(quote)\n",
    "words = remove_punctuation(words)\n",
    "\n",
    "pos = nltk.pos_tag(words)\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word = word.lower()\n",
    "    posTag = ptb_to_wordnet( pos[i][1] )\n",
    "    \n",
    "    if re.search( r'\\w+' , posTag , re.IGNORECASE ):\n",
    "        lemma = lemmatiser.lemmatize( words[i] , posTag )\n",
    "        print( f'{word} => {lemma}' )\n",
    "    else:\n",
    "        print( f'{word} => {word}' )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.1\n",
    "\n",
    "Create a list containing the unique adjectives that are occur in *Pride and Prejudice*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.2\n",
    "\n",
    "Stephen King is [reputed to have said](https://www.goodreads.com/quotes/430289-i-believe-the-road-to-hell-is-paved-with-adverbs) that â€œthe road to hell is paved with adverbs\", and many style guides similarly give writers the advice to avoid adverbs, especially those ending in '-ly'. \n",
    "\n",
    "Can you calculate, for each text in the corpus, the number of adverb ending in '-ly', measured as a percentage of the total number of words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execise 6.3\n",
    "\n",
    "Which text in the corpus has the highest number of modal verbs? The Penn Treebank code for 'modal auxialiaries' is MD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.4\n",
    "\n",
    "Extract all the sentences from *HeartOfDarkness.txt* that contain an adjective in the superlative form.  Write these sentences into a file named 'sentences.txt'. The code for the words in these category is 'JJS'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.5\n",
    "\n",
    "Extract all the sentences from *ARoomWithaView.txt* containing a form of the verb 'to see', in all tenses and conjugations and excepting the infitive form. In other words, extract sentences containing forms such as 'seen', 'saw' or 'seeing', but not 'see'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.6\n",
    "\n",
    "From *HeartOfDarkness.txt* , extract all sentnces containing the following combinations of categories: \n",
    "\n",
    "* Article - adverb - adjective - noun \n",
    "\n",
    "These categorties can be asigned the following codes:\n",
    "\n",
    "* Article: DT\n",
    "* Adverb: RB, RBR or RBS\n",
    "* Adjective: JJ, JJR or JJS\n",
    "* Noun: NN, NNP, NNPS or NNS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
