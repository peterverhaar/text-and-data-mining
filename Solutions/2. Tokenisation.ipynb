{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Exercise 2.1.\n",
    "\n",
    "The 'Corpus' that you have downloaded as part of this tutorial contains the full text of 'Pride and Prejudice'. \n",
    "Write code that can help you to answer the following questions about this text:\n",
    "\n",
    "* How many characters are there in the novel?\n",
    "* How many words does the novel contain?\n",
    "* How often does the novel mention the word \"marriage\"?\n",
    "* How long are the words in *Pride and Prejudice* on average (measured in number of characters)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from tdmh import *\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# This code 'moves down' in the folder system\n",
    "# because the folder 'Corpus' is on the same level as 'Solutions'\n",
    "path_parent = os.path.dirname(os.getcwd())\n",
    "path = join( path_parent , 'Corpus' , 'PrideandPrejudice.txt')\n",
    "\n",
    "# if 'Corpus' is in the same directory of this notebook, \n",
    "# you can use:\n",
    "# path = join( 'Corpus' , 'PrideandPrejudice.txt')\n",
    "\n",
    "fh = open( path , encoding = 'utf-8' )\n",
    "full_text = fh.read()\n",
    "\n",
    "nr_char = len(full_text)\n",
    "\n",
    "print( f'The novel contains { len(full_text) } characters. ' )\n",
    "\n",
    "words = word_tokenize(full_text)\n",
    "words = remove_punctuation(words)\n",
    "\n",
    "nr_words = len(words) \n",
    "\n",
    "print( f'The novel contains { nr_char } characters. ' )\n",
    "print( f'The word \"marriage\" occurs { nr_words } times.' )\n",
    "\n",
    "print( f'The words in the novel contain { nr_char / nr_words} characters on average. ' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2.\n",
    "\n",
    "Can you print the first five sentences of *Pride and Prejudice*?\n",
    "How many sentences does the novel contain in total?\n",
    "Building on the results of the previous exercise, can you calculate the average length of sentences? In other words, how many tokens do the sentences contain on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(full_text)\n",
    "\n",
    "print( f'The sentences in the novel contain { round( nr_words / nr_sentences , 3 ) } wordss on average. ' )\n",
    "\n",
    "\n",
    "print('\\nFirst five sentences:\\n')\n",
    "\n",
    "nr_sentences = len(sentences)\n",
    "for s in sentences[7:12]:\n",
    "    print( f'- {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3.\n",
    "\n",
    "Can you develop a word tokeniser yourself? Create a function yourself that can take a text as input and which can return a list with all the individual words.\n",
    "\n",
    "In such a function, you can use the `split()` method from `re`. This method enables you to divide a text into smaller parts, based on a regular expression. \n",
    "\n",
    "Also take into account the following requirements: \n",
    "\n",
    "* The function must store all the tokens in a case-insensitive way; the characters must all be stored either in upper or in lower case. \n",
    "* Words can be divided using spaces or the 'em dash', which is written using two condecutive hyphens. \n",
    "* Punctuation marks such as commas, exclampation marks or full stops at the end of a token must be removed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# function to tokenise a string into words\n",
    "def word_tokenise( text ):\n",
    "    tokens = []\n",
    "    text = text.lower()\n",
    "    text = re.sub( '--' , ' -- ' , text)\n",
    "    words = re.split( r'\\s+' , text )\n",
    "    for w in words:\n",
    "        w = w.strip( string.punctuation )\n",
    "        if re.search( r\"[a-zA-Z]\" , w ):\n",
    "            tokens.append(w)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "sentences = 'It was the best of times, it was the worst of times'\n",
    "words = word_tokenise(sentences)\n",
    "for w in words:\n",
    "    print(w)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
